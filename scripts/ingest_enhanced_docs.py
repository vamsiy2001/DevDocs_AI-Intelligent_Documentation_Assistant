"""
Ingest Enhanced Multi-Framework Documentation
Loads comprehensive docs about LangChain, LangGraph, FastAPI, Gradio, RAG, etc.
"""

import sys
import os

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.ingestion.enhanced_document_loader import EnhancedDocumentLoader
from src.ingestion.chunking import DocumentChunker
from src.retrieval import HybridRetriever
from src.config import settings


def main():
    """Load and ingest enhanced documentation"""
    
    print("\n" + "="*70)
    print("üìö ENHANCED DOCUMENTATION INGESTION")
    print("="*70)
    print("\nThis will load comprehensive documentation covering:")
    print("  ‚Ä¢ LangChain (overview, chains, agents, RAG)")
    print("  ‚Ä¢ LangGraph (stateful workflows, routing)")
    print("  ‚Ä¢ Vector Databases (Chroma, Pinecone, Qdrant, etc.)")
    print("  ‚Ä¢ Embeddings & Semantic Search")
    print("  ‚Ä¢ RAG Evaluation (RAGAS metrics)")
    print("  ‚Ä¢ Advanced RAG Techniques")
    print("  ‚Ä¢ FastAPI")
    print("  ‚Ä¢ Gradio")
    print("  ‚Ä¢ Prompt Engineering")
    print()
    
    # 1. Load enhanced documents
    print("üìÇ Loading enhanced documentation...")
    loader = EnhancedDocumentLoader()
    documents = loader.load_comprehensive_docs()
    
    print(f"\n‚úÖ Loaded {len(documents)} documents")
    
    # Show document breakdown
    frameworks = {}
    for doc in documents:
        fw = doc.metadata.get('framework', 'unknown')
        frameworks[fw] = frameworks.get(fw, 0) + 1
    
    print("\nüìä Document breakdown by framework:")
    for fw, count in frameworks.items():
        print(f"   ‚Ä¢ {fw}: {count} documents")
    
    # 2. Chunk documents
    print(f"\n‚úÇÔ∏è  Chunking documents...")
    chunker = DocumentChunker(chunk_size=500, chunk_overlap=50)
    chunks = chunker.recursive_character_split(documents)
    
    # Add source framework to chunk metadata
    print(f"‚úÖ Created {len(chunks)} chunks")
    
    # 3. Create vector store
    print(f"\nüíæ Creating vector store...")
    print(f"   This may take 2-3 minutes for embeddings...")
    
    retriever = HybridRetriever()
    success = retriever.create_vector_store(chunks)
    
    if success:
        print(f"\n{'='*70}")
        print("‚úÖ ENHANCED DOCUMENTATION INGESTED SUCCESSFULLY!")
        print('='*70)
        
        print(f"\nüìä Summary:")
        print(f"   ‚Ä¢ Source Documents: {len(documents)}")
        print(f"   ‚Ä¢ Chunks Created: {len(chunks)}")
        print(f"   ‚Ä¢ Frameworks: {', '.join(frameworks.keys())}")
        print(f"   ‚Ä¢ Vector Store: {settings.CHROMA_PATH}")
        
        print(f"\nüéØ Your RAG system can now answer questions about:")
        print(f"   ‚Ä¢ LangChain (chains, agents, memory)")
        print(f"   ‚Ä¢ LangGraph (workflows, routing)")
        print(f"   ‚Ä¢ RAG systems (evaluation, techniques)")
        print(f"   ‚Ä¢ Vector databases (Chroma, Pinecone, etc.)")
        print(f"   ‚Ä¢ Embeddings and semantic search")
        print(f"   ‚Ä¢ FastAPI and Gradio")
        print(f"   ‚Ä¢ Prompt engineering")
        
        print()
        
        return 0
    else:
        print("\n‚ùå Failed to create vector store")
        return 1


if __name__ == "__main__":
    try:
        exit(main())
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)